{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbdc73cb",
   "metadata": {},
   "source": [
    "\n",
    "# üì¶ Pipeline compact ‚Äî Barom√®tre 2024 ‚Üí `data.xlsx`\n",
    "\n",
    "**Objectif :** Refaire *exactement* les m√™mes traitements que ton script, mais **en m√©moire**, sans fichiers interm√©diaires inutiles.  \n",
    "**Sorties finales :**\n",
    "- `data.xlsx` ‚Äî dataset final pr√™t √† l'analyse / dashboard\n",
    "- `barometre_pipeline_log.csv` ‚Äî log synth√©tique du pipeline\n",
    "\n",
    "> Entr√©es attendues dans le m√™me dossier :  \n",
    "> - `2024-barometre-consommation.xlsx`  \n",
    "> - `2024-datamap.xlsx` (onglet **TEXTS**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "LOG = []\n",
    "\n",
    "def log(msg):\n",
    "    print(msg)\n",
    "    LOG.append(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4202e4",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Chargement des donn√©es brutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0211636",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chemins (adapter si besoin)\n",
    "PATH_DATA = Path(\"2024-barometre-consommation.xlsx\")\n",
    "PATH_DICT = Path(\"2024-datamap.xlsx\")\n",
    "\n",
    "# Lecture\n",
    "df = pd.read_excel(PATH_DATA)\n",
    "df_raw_shape = df.shape\n",
    "log(f\"üì• Loaded raw data: {df_raw_shape[0]} rows √ó {df_raw_shape[1]} cols\")\n",
    "\n",
    "# Dictionnaire / TEXTS\n",
    "df_texts = pd.read_excel(PATH_DICT, sheet_name=\"TEXTS\")\n",
    "df_texts.columns = [c.strip().upper() for c in df_texts.columns]\n",
    "\n",
    "# Normalisation TYPE/CODE si pr√©sents\n",
    "if \"TYPE\" in df_texts.columns:\n",
    "    type_norm = df_texts[\"TYPE\"].astype(str).str.strip().str.upper()\n",
    "    if \"CODE\" not in df_texts.columns:\n",
    "        df_texts[\"CODE\"] = pd.NA\n",
    "    df_texts.loc[type_norm.eq(\"TITLE\"), \"CODE\"] = 0\n",
    "\n",
    "if \"CODE\" in df_texts.columns:\n",
    "    df_texts[\"CODE\"] = pd.to_numeric(df_texts[\"CODE\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# On conserve les colonnes utiles si elles existent\n",
    "keep_cols = [c for c in [\"NAME\", \"CODE\", \"FR:L\"] if c in df_texts.columns]\n",
    "df_texts = df_texts[keep_cols].dropna(subset=[keep_cols[0]])\n",
    "log(f\"üìñ TEXTS dict loaded: {df_texts.shape[0]} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38906689",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Pr√©-nettoyage (colonnes vides / constantes / quasi vides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdfae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Colonnes vides\n",
    "empty_cols = df.columns[df.isna().all()].tolist()\n",
    "if empty_cols:\n",
    "    df = df.drop(columns=empty_cols)\n",
    "    log(f\"üóëÔ∏è Dropped empty columns: {len(empty_cols)}\")\n",
    "\n",
    "# Constantes\n",
    "constant_cols = [c for c in df.columns if df[c].nunique(dropna=False) <= 1]\n",
    "if constant_cols:\n",
    "    log(f\"‚öôÔ∏è Constant columns detected: {len(constant_cols)} (kept for s√©curit√©, pas de drop automatique)\")\n",
    "\n",
    "# Quasi vides (>95% NaN) ‚Äî on les retire\n",
    "mostly_empty = [c for c in df.columns if df[c].isna().mean() > 0.95]\n",
    "if mostly_empty:\n",
    "    df = df.drop(columns=mostly_empty)\n",
    "    log(f\"üí® Dropped mostly-empty columns (>95% NaN): {len(mostly_empty)}\")\n",
    "\n",
    "log(f\"‚úÖ Shape after pre-clean: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbdc18c",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Nettoyage s√©mantique l√©ger (d√©riv√©s, techniques, duplicats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cae911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "# Tech / routing (patterns fr√©quents)\n",
    "technical_patterns = [r\"^(AFRS|AFQ|SYS_|CELLULE|CEL)\"]\n",
    "for pat in technical_patterns:\n",
    "    cols_to_drop += [c for c in df.columns if re.match(pat, str(c))]\n",
    "\n",
    "# Multi-lignes suffixes _R\\d+$\n",
    "cols_to_drop += [c for c in df.columns if re.search(r\"_R\\d+$\", str(c))]\n",
    "\n",
    "# D√©duplique exacts (m√™me contenu)\n",
    "duplicated_cols = df.T.duplicated(keep=\"first\")\n",
    "dup_names = df.columns[duplicated_cols].tolist()\n",
    "cols_to_drop += dup_names\n",
    "\n",
    "cols_to_drop = sorted(set(cols_to_drop))\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors=\"ignore\")\n",
    "log(f\"üßπ Dropped routing/duplicate-like columns: {len(cols_to_drop)}\")\n",
    "log(f\"üìè Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5644ca",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Construction des mappings (code ‚Üí label) depuis `TEXTS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57021811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mappings par variable (pour colonnes cod√©es)\n",
    "label_mappings = {}\n",
    "if set([\"NAME\",\"CODE\",\"FR:L\"]).issubset(df_texts.columns):\n",
    "    for name in df_texts[\"NAME\"].dropna().astype(str).unique():\n",
    "        sub = df_texts[df_texts[\"NAME\"] == name].dropna(subset=[\"CODE\", \"FR:L\"])\n",
    "        if not sub.empty:\n",
    "            mapping = dict(zip(sub[\"CODE\"].astype(str), sub[\"FR:L\"].astype(str)))\n",
    "            label_mappings[name] = mapping\n",
    "log(f\"üî† Built {len(label_mappings)} variable-level mappings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c197d",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Fusion des questions multi-r√©ponses (`..._rX_cY`) avec labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pattern = r\"(.+?)_r(\\d+)_c\\d+$\"\n",
    "multi_groups = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    m = re.match(pattern, str(col))\n",
    "    if m:\n",
    "        root, code = m.group(1).strip(), m.group(2).strip()\n",
    "        multi_groups.setdefault(root, []).append((col, code))\n",
    "\n",
    "log(f\"üîç Detected multi-response groups: {len(multi_groups)}\")\n",
    "\n",
    "def combine_labels(row, items, label_map):\n",
    "    selected = []\n",
    "    for col, code in items:\n",
    "        val = row.get(col)\n",
    "        if pd.notna(val) and str(val).strip() not in [\"0\", \"\", \"nan\"]:\n",
    "            label = (label_map or {}).get(str(code))\n",
    "            selected.append(label if label else f\"Code {code}\")\n",
    "    return \", \".join([x for x in selected if x])\n",
    "\n",
    "for root, items in multi_groups.items():\n",
    "    # label map by NAME ~ root (approx)\n",
    "    label_map = None\n",
    "    # On tente un match souple: NAME contenant root (insensible √† la casse)\n",
    "    if label_mappings:\n",
    "        # Cherche le meilleur candidat\n",
    "        candidates = [k for k in label_mappings.keys() if root.lower() in k.lower()]\n",
    "        if candidates:\n",
    "            label_map = label_mappings[candidates[0]]\n",
    "    df[root + \"_COMBINED\"] = df.apply(lambda r: combine_labels(r, items, label_map), axis=1)\n",
    "    df = df.drop(columns=[c for c, _ in items], errors=\"ignore\")\n",
    "\n",
    "log(\"‚úÖ Merged multi-response groups into *_COMBINED columns\")\n",
    "log(f\"üìè Shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0348ec9a",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Remplacements sp√©cifiques (codes ‚Üí libell√©s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4967686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionnaires issus du script d'origine (extraits pertinents)\n",
    "region_map = {\n",
    "    \"UDA1\": \"√éle-de-France\",\"UDA2\": \"Hauts-de-France\",\"UDA3\": \"Grand Est\",\"UDA4\": \"Bourgogne-Franche-Comt√©\",\n",
    "    \"UDA5\": \"Auvergne-Rh√¥ne-Alpes\",\"UDA6\": \"Provence-Alpes-C√¥te d‚ÄôAzur\",\"UDA7\": \"Occitanie\",\n",
    "    \"UDA8\": \"Nouvelle-Aquitaine\",\"UDA9\": \"Pays de la Loire\",\n",
    "}\n",
    "urban_map = {\n",
    "    \"UU01\": \"Paris et grandes m√©tropoles\",\"UU02\": \"Grande ville (100k‚Äì500k hab.)\",\"UU03\": \"Ville moyenne (50k‚Äì100k hab.)\",\n",
    "    \"UU04\": \"Petite ville (20k‚Äì50k hab.)\",\"UU05\": \"Bourg / petite agglom√©ration\",\"UU06\": \"Rural p√©riurbain\",\n",
    "    \"UU07\": \"Rural isol√©\",\"UU08\": \"Autres / hors unit√© urbaine\",\"Hors unit√© urbaine\": \"Rural isol√©\"\n",
    "}\n",
    "qbu1_map = {1:\"Uniquement gratuitement\",2:\"Le plus souvent gratuitement, mais parfois de fa√ßon payante\",3:\"Autant gratuitement que de fa√ßon payante\",4:\"Le plus souvent de fa√ßon payante, mais parfois gratuitement\",5:\"Uniquement de fa√ßon payante\"}\n",
    "qbu12_map = {1:\"Tous les jours ou presque\",2:\"1 √† 5 fois par semaine\",3:\"1 √† 3 fois par mois\",4:\"Moins souvent\",5:\"Jamais\"}\n",
    "\n",
    "def safe_replace_contains(df, pattern_substr, mapping):\n",
    "    matched = [c for c in df.columns if pattern_substr.lower() in str(c).lower()]\n",
    "    for col in matched:\n",
    "        df[col] = df[col].replace(mapping)\n",
    "        log(f\"‚ÜîÔ∏è Replaced codes in: {col} ({len(mapping)} items)\")\n",
    "\n",
    "# Region / Agglo\n",
    "if \"REG\" in df.columns: df[\"REG\"] = df[\"REG\"].replace(region_map)\n",
    "if \"AGGLOIFOP0\" in df.columns: df[\"AGGLOIFOP0\"] = df[\"AGGLOIFOP0\"].replace(urban_map)\n",
    "\n",
    "# QBU1 / QBU12 + quelques patterns du script\n",
    "safe_replace_contains(df, \"QBU1\", qbu1_map)\n",
    "safe_replace_contains(df, \"QBU12\", qbu12_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf508620",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Renommage final des colonnes (sch√©ma analytique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9945c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rename_dict = {\n",
    "    \"SEXE - Vous √™tes... ?\": \"sexe\",\n",
    "    \"AGE - Quel √¢ge avez-vous ? Merci de noter votre √¢ge dans le cadre ci-dessous :\": \"age\",\n",
    "    \"AGGLOIFOP0\": \"type_agglomeration\",\n",
    "    \"TYPCOM\": \"type_commune\",\n",
    "    \"TAILCOM\": \"taille_commune\",\n",
    "    \"DPT\": \"departement\",\n",
    "    \"REG\": \"region\",\n",
    "    \"SITI - Actuellement, quelle est votre situation ?\": \"situation_personnelle\",\n",
    "    \"PPIA - Plus pr√©cis√©ment, quelle est votre profession principale ou, si vous ne travaillez pas actuellement, la derni√®re profession principale que vous avez exerc√©e ? Attention, si vous n‚Äôavez fait dans votre vie que des petits boulots (ex : job d\": \"profession_principale\",\n",
    "    \"RECPPIA\": \"statut_professionnel\",\n",
    "    \"STC - Vous exercez cette profession comme‚Ä¶ ? Si vous exercez plusieurs emplois, d√©crivez uniquement votre emploi principal.\": \"statut_emploi\",\n",
    "    \"STCA\": \"categorie_socio_professionnelle\",\n",
    "    \"STATUT - Au sein de votre foyer, quelle est votre situation ?\": \"statut_foyer\",\n",
    "    \"FOYER - De combien de personnes se compose votre foyer y compris vous-m√™me ?\": \"taille_foyer\",\n",
    "    \"ENF - Au total, combien y a-t-il d‚Äôenfants de moins de 18 ans dans votre foyer ?\": \"nb_enfants\",\n",
    "    \"RS6 - A quelle fr√©quence utilisez-vous Internet ou des applications, quels que soient le lieu d‚Äôutilisation et l‚Äôappareil de connexion ?\": \"frequence_internet\",\n",
    "    \"Q2 - √Ä quelle fr√©quence consommez-vous sur Internet chacun des produits ou services culturels d√©mat√©rialis√©s suivants ? Une r√©ponse par ligne. Vous consommez sur Internet ‚Ä¶_r1\": \"frequence_conso_culturelle\",\n",
    "    \"Q5 - Plus pr√©cis√©ment, pour chacun des produits ou services culturels suivants, diriez-vous que vous les consommez‚Ä¶ Une r√©ponse par ligne. sur Internet ‚Ä¶_r1\": \"type_conso_legale_ou_illegale\",\n",
    "    \"Q7 - Concernant votre consommation de biens culturels d√©mat√©rialis√©s, diriez-vous qu‚Äôaujourd‚Äôhui :\": \"evolution_conso_legale\",\n",
    "    \"QBU1 - Vous nous avez dit consommer de fa√ßon d√©mat√©rialis√©e les contenus culturels et sportifs suivants. Veuillez indiquer pour chacun d‚Äôeux si vous les consommez gratuitement ou de fa√ßon payante. On parle toujours de contenus culturels et spor_r1\": \"gratuit_ou_payant\",\n",
    "    \"QBU2 - De fa√ßon g√©n√©rale, quel montant d√©pensez-vous en moyenne chaque mois pour votre consommation de [% ListLabel(Q1List,AFFi1) %] [% ListLabel(Q1List,AFFi2) %] [% ListLabel(Q1List,AFFi3) %] [% ListLabel(Q1List,AFFi4) %] [% ListLabel(Q1List,AFFi5\": \"depense_mensuelle_culturelle\",\n",
    "    \"- Utilisez-vous des applications ¬´ crack√©es ¬ª que vous avez t√©l√©charg√©es sur des stores d‚Äôapplications alternatifs (comme AppValley ou Tutuapp par exemple) ou via des APKs, permettant l‚Äôacc√®s √† des offres payantes sans payer ? Vou_1\": \"utilisation_applis_crackees\",\n",
    "    \"QBU12 - Utilisez-vous des logiciels, des applications ou des sites internet permettant de convertir des contenus consult√©s en streaming (films, s√©ries, musique vus sur une plateforme) en un contenu √† t√©l√©charger (qui permettent par exemple de conv_r1\": \"utilisation_telechargement_streaming\",\n",
    "    \"RS8 - Et vous arrive-t-il de faire des r√©glages de DNS ?\": \"reglages_dns\",\n",
    "    \"RS7BIS - Au cours des 12 derniers mois, avez-vous utilis√© au moins un VPN √† titre personnel ?\": \"utilisation_vpn\",\n",
    "    \"QBU5a - Et au cours des 12 derniers mois, sur quels appareils avez-vous consomm√© ces contenus culturels et sportifs la plupart du temps ? Vous pouvez s√©lectionner plusieurs r√©ponses par ligne. G√©n√©ralement, ‚Ä¶_COMBINED\": \"appareils_conso_musique_videos\",\n",
    "    \"QBU5b - Et au cours des 12 derniers mois, sur quels appareils avez-vous consomm√© ces contenus culturels et sportifs la plupart du temps ? Vous pouvez s√©lectionner plusieurs r√©ponses par ligne. G√©n√©ralement, ‚Ä¶_COMBINED\": \"appareils_conso_films_series\",\n",
    "    \"RS12BIS - Avez-vous acc√®s aux fournisseurs de services payants suivants ? Attention, nous parlons ici des offres auxquelles vous avez acc√®s en payant (vous ou une autre personne de votre foyer) ou en b√©n√©ficiant d‚Äôun compte d‚Äôune personne ext_COMBINED\": \"acces_services_payants\",\n",
    "    \"RS16BIS - √Ä qui appartiennent ces codes d‚Äôacc√®s ext√©rieurs √† votre foyer que vous utilisez ? Vous pouvez s√©lectionner plusieurs r√©ponses par ligne. Pour_COMBINED\": \"provenance_codes_acces_exterieurs\"\n",
    "}\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# S√©lection des colonnes cibles si pr√©sentes\n",
    "cols_keep = [\n",
    "    \"sexe\",\"age\",\"region\",\"type_agglomeration\",\n",
    "    \"situation_personnelle\",\"profession_principale\",\"statut_emploi\",\n",
    "    \"frequence_internet\",\"frequence_conso_culturelle\",\n",
    "    \"type_conso_legale_ou_illegale\",\"evolution_conso_legale\",\n",
    "    \"gratuit_ou_payant\",\"depense_mensuelle_culturelle\",\n",
    "    \"appareils_conso_musique_videos\",\"appareils_conso_films_series\",\n",
    "    \"utilisation_vpn\",\"utilisation_applis_crackees\",\n",
    "    \"utilisation_telechargement_streaming\",\"reglages_dns\",\n",
    "    \"acces_services_payants\",\"provenance_codes_acces_exterieurs\",\n",
    "    \"taille_foyer\",\"nb_enfants\",\"statut_foyer\"\n",
    "]\n",
    "existing = [c for c in cols_keep if c in df.columns]\n",
    "df = df[existing].copy()\n",
    "log(f\"üß≠ Selected {len(existing)} analytical columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153427f",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Finitions (qualit√©, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Types & noms\n",
    "df.columns = [c.lower().replace(\" \", \"_\") for c in df.columns]\n",
    "if \"age\" in df.columns:\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Trim strings\n",
    "for c in df.select_dtypes(\"object\").columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# D√©doublonnage\n",
    "dupes = df.duplicated().sum()\n",
    "if dupes:\n",
    "    df = df.drop_duplicates()\n",
    "log(f\"üß© Duplicates removed: {dupes}\")\n",
    "log(f\"‚úÖ Final shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39968047",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Sauvegardes finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Dataset final\n",
    "df.to_excel(\"data.xlsx\", index=False, engine=\"openpyxl\")\n",
    "log(\"üíæ Saved dataset ‚Üí data.xlsx\")\n",
    "\n",
    "# 2) Log pipeline\n",
    "pd.Series(LOG, name=\"log\").to_csv(\"barometre_pipeline_log.csv\", index=False, encoding=\"utf-8\")\n",
    "log(\"üßæ Saved log ‚Üí barometre_pipeline_log.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
